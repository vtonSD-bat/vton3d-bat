{
 "cells": [
  {
   "cell_type": "code",
   "id": "a54a567048d96b66",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-27T10:35:46.201422Z",
     "start_time": "2025-11-27T10:35:44.230365Z"
    }
   },
   "source": [
    "\n",
    "from vggt.models.vggt import VGGT"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T10:35:15.213599Z",
     "start_time": "2025-11-27T10:35:15.207655Z"
    }
   },
   "source": [
    "\n",
    "from vton3d.utils import test"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "f86cd5ab1170925b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T10:35:16.238415Z",
     "start_time": "2025-11-27T10:35:16.232764Z"
    }
   },
   "source": [
    "print(test.e())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "1238e1a91cee3af6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T10:35:16.977789Z",
     "start_time": "2025-11-27T10:35:16.968135Z"
    }
   },
   "source": [
    "VGGT"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vggt.models.vggt.VGGT"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9439e87afd75d9f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T14:52:45.655620Z",
     "start_time": "2025-11-25T14:52:45.641350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__']\n"
     ]
    }
   ],
   "source": [
    "import vton3d\n",
    "\n",
    "print(dir(vton3d))\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "d9239eec37733874",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T09:20:06.330017Z",
     "start_time": "2025-12-30T09:20:06.202565Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Pfad zu deinem Sapiens-Pytorch-Inference Ordner anpassen\n",
    "sapiens_dir = \"../Sapiens-Pytorch-Inference\"\n",
    "\n",
    "if not os.path.isdir(sapiens_dir):\n",
    "    raise FileNotFoundError(f\"Sapiens-Ordner nicht gefunden: {sapiens_dir}\")\n",
    "\n",
    "# Repo in sys.path eintragen, damit der Import klappt\n",
    "sys.path.insert(0, sapiens_dir)\n",
    "\n",
    "from sapiens_inference import (\n",
    "    SapiensDepth,\n",
    "    SapiensDepthType,\n",
    "    SapiensSegmentation,\n",
    "    SapiensSegmentationType,\n",
    "    SapiensConfig,\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T09:21:19.145732Z",
     "start_time": "2025-12-30T09:21:04.007243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Konfiguration\n",
    "config = SapiensConfig()\n",
    "config.depth_type = SapiensDepthType.DEPTH_1B\n",
    "config.segmentation_type = SapiensSegmentationType.SEGMENTATION_1B\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    config.device = \"cuda\"\n",
    "else:\n",
    "    print(\"Keine GPU gefunden, verwende CPU.\")\n",
    "    config.device = \"cpu\"\n",
    "\n",
    "# Modelle laden (damit die Modelle im richtigen Ordner landen)\n",
    "orig_cwd = os.getcwd()\n",
    "try:\n",
    "    os.makedirs(os.path.join(sapiens_dir, \"models\"), exist_ok=True)\n",
    "    os.chdir(sapiens_dir)\n",
    "    depth_predictor = SapiensDepth(config.depth_type, config.device, config.dtype)\n",
    "    seg_predictor = SapiensSegmentation(config.segmentation_type, config.device, config.dtype)\n",
    "finally:\n",
    "    os.chdir(orig_cwd)\n",
    "\n",
    "print(\"Modelle geladen auf Gerät:\", config.device)\n"
   ],
   "id": "bc61d8d447f604c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelle geladen auf Gerät: cuda\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T09:21:29.128669Z",
     "start_time": "2025-12-30T09:21:27.977408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run_sapiens_on_image(img_path):\n",
    "    # Bild laden (RGB) und nach BGR konvertieren wie in deinem Skript\n",
    "    pil = Image.open(img_path).convert(\"RGB\")\n",
    "    rgb_np = np.array(pil)\n",
    "    bgr_np = cv2.cvtColor(rgb_np, cv2.COLOR_RGB2BGR)\n",
    "    H, W = bgr_np.shape[:2]\n",
    "\n",
    "    # Segmentation\n",
    "    seg_logits = seg_predictor(bgr_np)\n",
    "    if isinstance(seg_logits, torch.Tensor):\n",
    "        seg_map = seg_logits.squeeze().cpu().numpy()\n",
    "    else:\n",
    "        seg_map = seg_logits\n",
    "\n",
    "    if seg_map.shape != (H, W):\n",
    "        seg_map = cv2.resize(seg_map, (W, H), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    human_mask = (seg_map > 0.5).astype(np.uint8)\n",
    "\n",
    "    # Depth\n",
    "    depth_raw = depth_predictor(bgr_np)\n",
    "    if isinstance(depth_raw, torch.Tensor):\n",
    "        depth_np = depth_raw.squeeze().cpu().numpy()\n",
    "    else:\n",
    "        depth_np = depth_raw\n",
    "\n",
    "    d_min, d_max = np.nanmin(depth_np), np.nanmax(depth_np)\n",
    "    depth_norm = (depth_np - d_min) / (d_max - d_min + 1e-8)\n",
    "\n",
    "    # Hintergrund auf \"weit weg\" setzen, wie in deinem Skript\n",
    "    modified_depth = np.where(human_mask == 1, depth_norm, 1.0)\n",
    "    modified_8u = (modified_depth * 255).astype(np.uint8)\n",
    "    depth_color_bgr = cv2.applyColorMap(modified_8u, cv2.COLORMAP_TURBO)\n",
    "    depth_color_rgb = cv2.cvtColor(depth_color_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    return rgb_np, human_mask, depth_color_rgb\n"
   ],
   "id": "4d1788fd3e6a366",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-12-30T09:22:54.560983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_image = \"../data/flo_16/real/images/florian_0000.jpg\"\n",
    "\n",
    "rgb, mask, depth_vis = run_sapiens_on_image(test_image)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Original\")\n",
    "plt.imshow(rgb)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Human-Maske\")\n",
    "plt.imshow(mask, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Depth (modifiziert)\")\n",
    "plt.imshow(depth_vis)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ],
   "id": "3ac4a92367ee5158",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "47ff2e54e5d96694"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
